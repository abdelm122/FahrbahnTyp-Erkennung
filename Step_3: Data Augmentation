# 03_data_augmentation_x3_simple.py
# ------------------------------------------------------------
# Input:
#   STEP_2/npz/train_norm.npz   (X: [N,T,6], y:[N])
#   STEP_2/npz/val_norm.npz
#   STEP_2/npz/test_norm.npz
#
# Output:
#   STEP_3/npz/train_aug_x3.npz (X: [3N,T,6], y:[3N])
#   STEP_3/npz/val_norm.npz     (nur kopiert)
#   STEP_3/npz/test_norm.npz    (nur kopiert)
#   STEP_3/aug_config.json
# ------------------------------------------------------------

import os
import json
import numpy as np

# =========================
# EINSTELLUNGEN
# =========================
IN_DIR = r"./STEP_2/npz"
OUT_DIR = r"./STEP_3"

SEED = 123
FACTOR = 3  # 3 = Original + 2 Aug-Kopien

# Augmentation-Stärken (moderate Werte)
JITTER_SIGMA = 0.03         # Rauschen
SCALING_SIGMA = 0.05        # Gain pro Kanal
P_MASK = 0.7                # Wahrscheinlichkeit für Time-Mask
AXIS_MIX_P = 0.3            # Wahrscheinlichkeit für Axis-Mix
AXIS_MIX_STRENGTH = 0.02    # Stärke für Axis-Mix


# =========================
# I/O
# =========================
def load_npz(path):
    if not os.path.isfile(path):
        raise FileNotFoundError(f"Datei nicht gefunden: {path}")
    d = np.load(path)
    if "X" not in d or "y" not in d:
        raise ValueError(f"NPZ braucht Keys X und y: {path}")
    X = d["X"].astype(np.float32, copy=False)
    y = d["y"].astype(np.int64, copy=False)

    if X.ndim != 3 or X.shape[2] != 6:
        raise ValueError(f"X muss [N,T,6] sein. Bekommen: {X.shape}")
    if y.ndim != 1 or y.shape[0] != X.shape[0]:
        raise ValueError(f"y muss [N] sein und zu X passen. X:{X.shape} y:{y.shape}")

    return X, y


def save_npz(path, X, y):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    np.savez_compressed(path, X=X.astype(np.float32, copy=False), y=y.astype(np.int64, copy=False))


# =========================
# AUGMENTATION (einfach)
# =========================
def aug_jitter(X, rng, sigma):
    noise = rng.normal(0.0, sigma, size=X.shape).astype(np.float32)
    return X + noise


def aug_scaling(X, rng, scale_sigma):
    gains = (1.0 + rng.normal(0.0, scale_sigma, size=(1, 1, X.shape[2]))).astype(np.float32)
    return X * gains


def aug_time_shift(X, rng, max_shift):
    if max_shift <= 0:
        return X
    shift = int(rng.integers(-max_shift, max_shift + 1))
    return np.roll(X, shift=shift, axis=1)


def aug_time_mask(X, rng, max_mask_len):
    if max_mask_len <= 0:
        return X
    T = X.shape[1]
    mask_len = int(rng.integers(0, max_mask_len + 1))
    if mask_len <= 0 or mask_len >= T:
        return X

    start = int(rng.integers(0, T - mask_len))
    X2 = X.copy()
    X2[:, start:start + mask_len, :] = 0.0
    return X2


def aug_axis_mix(X, rng, strength):
    # leichte Mischung der 6 Kanäle (klein halten!)
    if strength <= 0:
        return X

    C = X.shape[2]
    M = np.eye(C, dtype=np.float32)

    # ein paar Off-diagonal Werte
    for _ in range(8):
        i = int(rng.integers(0, C))
        j = int(rng.integers(0, C))
        if i != j:
            M[i, j] += float(rng.normal(0.0, strength))

    # stabilisieren
    row_norms = np.linalg.norm(M, axis=1, keepdims=True)
    M = M / np.maximum(row_norms, 1e-6)

    return np.einsum("ntc,cd->ntd", X, M).astype(np.float32)


def augment_batch(X, rng):
    # moderate defaults passend zu normalisierten Daten
    T = X.shape[1]
    max_shift = max(1, T // 20)      # ca. 5%
    max_mask_len = max(1, T // 25)   # kurzer dropout

    X2 = X
    X2 = aug_jitter(X2, rng, JITTER_SIGMA)
    X2 = aug_scaling(X2, rng, SCALING_SIGMA)
    X2 = aug_time_shift(X2, rng, max_shift)

    if rng.random() < P_MASK:
        X2 = aug_time_mask(X2, rng, max_mask_len)

    if rng.random() < AXIS_MIX_P:
        X2 = aug_axis_mix(X2, rng, AXIS_MIX_STRENGTH)

    return X2.astype(np.float32)


# =========================
# MAIN
# =========================
def main():
    print("Starte Step 3: Data Augmentation x3")
    print("IN_DIR :", os.path.abspath(IN_DIR))
    print("OUT_DIR:", os.path.abspath(OUT_DIR))

    train_path = os.path.join(IN_DIR, "train_norm.npz")
    val_path = os.path.join(IN_DIR, "val_norm.npz")
    test_path = os.path.join(IN_DIR, "test_norm.npz")

    X_train, y_train = load_npz(train_path)
    X_val, y_val = load_npz(val_path)
    X_test, y_test = load_npz(test_path)

    print("\nGeladen:")
    print("  Train:", X_train.shape, y_train.shape)
    print("  Val  :", X_val.shape, y_val.shape)
    print("  Test :", X_test.shape, y_test.shape)

    rng = np.random.default_rng(SEED)

    # Wir bauen: Original + 2 Augmentierungen
    X0 = X_train
    y0 = y_train

    X1 = augment_batch(X_train, rng)
    X2 = augment_batch(X_train, rng)

    X_aug = np.concatenate([X0, X1, X2], axis=0).astype(np.float32)
    y_aug = np.concatenate([y0, y0, y0], axis=0).astype(np.int64)

    # Shuffle
    idx = rng.permutation(X_aug.shape[0])
    X_aug = X_aug[idx]
    y_aug = y_aug[idx]

    # Output
    out_npz = os.path.join(OUT_DIR, "npz")
    os.makedirs(out_npz, exist_ok=True)

    save_npz(os.path.join(out_npz, "train_aug_x3.npz"), X_aug, y_aug)
    save_npz(os.path.join(out_npz, "val_norm.npz"), X_val, y_val)
    save_npz(os.path.join(out_npz, "test_norm.npz"), X_test, y_test)

    cfg = {
        "factor": FACTOR,
        "seed": SEED,
        "jitter_sigma": JITTER_SIGMA,
        "scaling_sigma": SCALING_SIGMA,
        "p_mask": P_MASK,
        "axis_mix_p": AXIS_MIX_P,
        "axis_mix_strength": AXIS_MIX_STRENGTH,
        "note": "Val/Test unverändert. Train = Original + 2 augmentierte Kopien."
    }

    os.makedirs(OUT_DIR, exist_ok=True)
    with open(os.path.join(OUT_DIR, "aug_config.json"), "w", encoding="utf-8") as f:
        json.dump(cfg, f, ensure_ascii=False, indent=2)

    print("\nFERTIG")
    print("Train vorher:", X_train.shape[0], "Train nachher:", X_aug.shape[0])
    print("Outputs:")
    print(" ", os.path.join(out_npz, "train_aug_x3.npz"))
    print(" ", os.path.join(out_npz, "val_norm.npz"))
    print(" ", os.path.join(out_npz, "test_norm.npz"))
    print(" ", os.path.join(OUT_DIR, "aug_config.json"))


if __name__ == "__main__":
    main()

