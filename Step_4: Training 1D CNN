# 04_training_tiny_1dcnn_simple.py
# ------------------------------------------------------------
#
# Input:
#   STEP_3/npz/train_aug_x3.npz  (X: [N,T,6], y:[N])
#   STEP_3/npz/val_norm.npz      (X: [N,T,6], y:[N])
#
# Output:
#   STEP_4/best_model.keras
#   STEP_4/final_model.keras
#   STEP_4/model_float.tflite
#   STEP_4/train_history.json
#   STEP_4/train_config.json
# ------------------------------------------------------------

import os
import json
import numpy as np

# TensorFlow
try:
    import tensorflow as tf
except ImportError:
    raise SystemExit(
        "TensorFlow fehlt. Installiere es z.B. mit:\n"
        "pip install tensorflow"
    )

# =========================
# EINSTELLUNGEN
# =========================
IN_DIR = r"./STEP_3/npz"
OUT_DIR = r"./STEP_4"
META_STEP1 = r"./STEP_1/metadata.json"   # optional für Klassen-Namen

SEED = 42
EPOCHS = 80
BATCH_SIZE = 128
LR = 1e-3
USE_CLASS_WEIGHTS = False   # True, wenn du Imbalance hast


CHANNELS = ["ax_g", "ay_g", "az_g", "gx_dps", "gy_dps", "gz_dps"]


# =========================
# HELFER
# =========================
def set_seed(seed):
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)


def load_npz(path):
    if not os.path.isfile(path):
        raise FileNotFoundError(f"Datei nicht gefunden: {path}")

    d = np.load(path)
    if "X" not in d or "y" not in d:
        raise ValueError(f"NPZ muss Keys X und y enthalten: {path}")

    X = d["X"].astype(np.float32, copy=False)
    y = d["y"].astype(np.int64, copy=False)

    if X.ndim != 3 or X.shape[2] != 6:
        raise ValueError(f"X muss [N,T,6] sein. Bekommen: {X.shape} in {path}")
    if y.ndim != 1 or y.shape[0] != X.shape[0]:
        raise ValueError(f"y muss [N] sein und zu X passen. X:{X.shape} y:{y.shape} in {path}")

    return X, y


def try_load_classnames(meta_path):
    if not meta_path or not os.path.isfile(meta_path):
        return None
    try:
        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)
        classes = meta.get("classes", None)
        if isinstance(classes, list):
            return {i: name for i, name in enumerate(classes)}
    except Exception:
        return None
    return None


def compute_class_weights(y, num_classes):
    counts = np.bincount(y, minlength=num_classes).astype(np.float32)
    counts = np.maximum(counts, 1.0)
    inv = 1.0 / counts
    weights = inv * (counts.sum() / num_classes)
    return {i: float(weights[i]) for i in range(num_classes)}


def build_tiny_1dcnn(T, C, num_classes):
    inp = tf.keras.Input(shape=(T, C), name="imu_window")

    x = tf.keras.layers.Conv1D(16, 7, padding="same", use_bias=False)(inp)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)
    x = tf.keras.layers.MaxPool1D(2)(x)

    x = tf.keras.layers.Conv1D(24, 5, padding="same", use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)
    x = tf.keras.layers.MaxPool1D(2)(x)

    x = tf.keras.layers.Conv1D(32, 3, padding="same", use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)

    x = tf.keras.layers.GlobalAveragePooling1D()(x)
    x = tf.keras.layers.Dense(32, activation="relu")(x)
    x = tf.keras.layers.Dropout(0.20)(x)

    out = tf.keras.layers.Dense(num_classes, activation="softmax", name="class_prob")(x)

    model = tf.keras.Model(inp, out, name="tiny_1dcnn")
    return model


def export_float_tflite(model, out_path):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open(out_path, "wb") as f:
        f.write(tflite_model)


# =========================
# MAIN
# =========================
def main():
    set_seed(SEED)

    print("Starte Step 4: Training Tiny 1D CNN")
    print("IN_DIR :", os.path.abspath(IN_DIR))
    print("OUT_DIR:", os.path.abspath(OUT_DIR))
    print("Settings: epochs =", EPOCHS, "| batch =", BATCH_SIZE, "| lr =", LR)

    train_path = os.path.join(IN_DIR, "train_aug_x3.npz")
    val_path = os.path.join(IN_DIR, "val_norm.npz")

    X_train, y_train = load_npz(train_path)
    X_val, y_val = load_npz(val_path)

    print("\nDaten geladen:")
    print("  Train:", X_train.shape, y_train.shape)
    print("  Val  :", X_val.shape, y_val.shape)

    T, C = X_train.shape[1], X_train.shape[2]
    num_classes = int(max(y_train.max(), y_val.max()) + 1)

    if X_val.shape[1] != T or X_val.shape[2] != C:
        raise RuntimeError("Train und Val haben unterschiedliche Shapes. Prüfe Step 1/2/3.")

    class_names = try_load_classnames(META_STEP1)

    # Modell
    model = build_tiny_1dcnn(T, C, num_classes)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),
        loss="sparse_categorical_crossentropy",
        metrics=[
            tf.keras.metrics.SparseCategoricalAccuracy(name="acc"),
        ],
    )

    model.summary()

    # Callbacks
    os.makedirs(OUT_DIR, exist_ok=True)
    best_path = os.path.join(OUT_DIR, "best_model.keras")
    final_path = os.path.join(OUT_DIR, "final_model.keras")

    callbacks = [
        tf.keras.callbacks.ModelCheckpoint(
            filepath=best_path,
            monitor="val_acc",
            mode="max",
            save_best_only=True,
            verbose=1,
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor="val_acc",
            mode="max",
            patience=15,
            restore_best_weights=True,
            verbose=1,
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="val_loss",
            factor=0.5,
            patience=6,
            min_lr=1e-5,
            verbose=1,
        ),
    ]

    # Class weights optional
    class_weights = None
    if USE_CLASS_WEIGHTS:
        class_weights = compute_class_weights(y_train, num_classes)
        print("\nClass weights aktiv:")
        for k, v in class_weights.items():
            name = class_names.get(k, str(k)) if class_names else str(k)
            print(f"  {k} ({name}) -> {v:.3f}")

    # Training
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        shuffle=True,
        callbacks=callbacks,
        class_weight=class_weights,
        verbose=2
    )

    # Speichern final
    model.save(final_path)

    # TFLite export
    tflite_path = os.path.join(OUT_DIR, "model_float.tflite")
    export_float_tflite(model, tflite_path)

    # History speichern
    hist_path = os.path.join(OUT_DIR, "train_history.json")
    with open(hist_path, "w", encoding="utf-8") as f:
        json.dump(history.history, f, ensure_ascii=False, indent=2)

    # Config speichern
    cfg = {
        "seed": SEED,
        "epochs": EPOCHS,
        "batch_size": BATCH_SIZE,
        "learning_rate": LR,
        "use_class_weights": bool(USE_CLASS_WEIGHTS),
        "input_shape": [int(T), int(C)],
        "num_classes": int(num_classes),
        "channels": CHANNELS,
        "paths": {
            "train": train_path,
            "val": val_path,
            "best_model": best_path,
            "final_model": final_path,
            "tflite_float": tflite_path,
            "history": hist_path,
        }
    }
    with open(os.path.join(OUT_DIR, "train_config.json"), "w", encoding="utf-8") as f:
        json.dump(cfg, f, ensure_ascii=False, indent=2)

    # Report
    print("\nStep 4 fertig ✅")
    print("Klassen:", num_classes)
    if class_names:
        print("Klassen-Mapping:")
        for i in range(num_classes):
            print(f"  {i}: {class_names.get(i, str(i))}")

    total_params = model.count_params()
    print("Total Params:", total_params)

    if "val_acc" in history.history and len(history.history["val_acc"]) > 0:
        best_val = float(np.max(history.history["val_acc"]))
        last_val = float(history.history["val_acc"][-1])
        print(f"Val acc: best={best_val:.4f} | last={last_val:.4f}")

    print("\nOutputs in:", os.path.abspath(OUT_DIR))
    print("  best_model.keras")
    print("  final_model.keras")
    print("  model_float.tflite")
    print("  train_history.json")
    print("  train_config.json")


if __name__ == "__main__":
    main()

